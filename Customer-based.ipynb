{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nominated-defensive",
   "metadata": {},
   "source": [
    "### 4.4 Method 4: Customers-based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incorporated-backing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-22\n"
     ]
    }
   ],
   "source": [
    "#Due to the large size of dataset, we will only use 0.05% of data in the modelling.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "transactions_df = pd.read_csv('./data/transactions_train.csv')\n",
    "customer_df = pd.read_csv('./data/customers.csv')\n",
    "discarded_transactions, selected_transactions = train_test_split(transactions_df, test_size=0.0005)\n",
    "\n",
    "#Change string to datetime format\n",
    "from datetime import datetime, timedelta\n",
    "selected_transactions['t_dat'] = selected_transactions['t_dat'].apply(lambda x :datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "#import customer dataframe, and create a column called age_group based on customer age\n",
    "def agegroup(x):\n",
    "    if x<=18:\n",
    "        return 1\n",
    "    elif x>18 and x<=35:\n",
    "        return 2\n",
    "    elif x>35 and x<= 50:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "customer_df['age_group'] = customer_df['age'].apply(agegroup)\n",
    "customer_df = customer_df[['customer_id', 'age_group']]\n",
    "\n",
    "#merge age_group to selected_transactions\n",
    "selected_transactions = pd.merge(selected_transactions, customer_df, on='customer_id')\n",
    "\n",
    "selected_transactions = selected_transactions[['t_dat','customer_id','article_id','age_group']]\n",
    "print(max(transactions_df['t_dat']))\n",
    "#maximum date is '2020-09-22'\n",
    "\n",
    "#Use the transaction in latest 6 month as test set\n",
    "test_set = selected_transactions[selected_transactions['t_dat'] >= datetime.strptime('2020-03-22', '%Y-%m-%d')]\n",
    "#Test set is around 24.9% of the selected dataset.\n",
    "\n",
    "training_set = selected_transactions[selected_transactions['t_dat'] < datetime.strptime('2020-03-22', '%Y-%m-%d')]\n",
    "training_set = training_set.groupby([\"customer_id\",\"article_id\", \"age_group\"])[\"t_dat\"].count().reset_index(name='counts')\n",
    "\n",
    "#Create a matrix to indicate whether a customer has purchased a product.\n",
    "similarity_matrix = pd.pivot_table(training_set,values='counts',index='customer_id',columns='article_id')\n",
    "similarity_matrix = similarity_matrix.fillna(0)\n",
    "\n",
    "#Generate a matrix of cosine similarity between customers.\n",
    "cosine = cosine_similarity(similarity_matrix)\n",
    "np.fill_diagonal(cosine, 0)\n",
    "similarity = pd.DataFrame(cosine, index=similarity_matrix.index)\n",
    "similarity.columns = similarity_matrix.index\n",
    "\n",
    "#Find the top 20 similar customers for each customer\n",
    "neighbours = similarity.apply(lambda x: pd.Series(x.sort_values(ascending=False)\n",
    "           .iloc[:20].index, \n",
    "          index=['top{}'.format(i) for i in range(1, 21)]), axis=1)\n",
    "\n",
    "\n",
    "#count the number of purchases of each product in each age_group\n",
    "purchase_counts = training_set.groupby([\"age_group\",\"article_id\"])['counts'].sum().reset_index(name='counts')\n",
    "\n",
    "#generate a dataframe for each age group\n",
    "age_group1 = purchase_counts.loc[purchase_counts['age_group'] == 1]\n",
    "age_group2 = purchase_counts.loc[purchase_counts['age_group'] == 2]\n",
    "age_group3 = purchase_counts.loc[purchase_counts['age_group'] == 3]\n",
    "age_group4 = purchase_counts.loc[purchase_counts['age_group'] == 4]\n",
    "\n",
    "def popular_products(age_group):\n",
    "    age_group = age_group.sort_values(by=['counts'], ascending = False)\n",
    "    age_group = age_group.iloc[:12,:]['article_id'].tolist()\n",
    "    return age_group\n",
    "\n",
    "#Find the top 12 most popular products for each age group.\n",
    "popular_product = []\n",
    "popular_product.append(popular_products(age_group1))\n",
    "popular_product.append(popular_products(age_group2))\n",
    "popular_product.append(popular_products(age_group3))\n",
    "popular_product.append(popular_products(age_group4))\n",
    "\n",
    "\n",
    "#get_kitems_customer_recommendations will take in the customer_id and the number of products to predict, and return a list of product_id.\n",
    "def purchased_products(similarity_matrix, customer_id):\n",
    "    a = similarity_matrix.loc[[customer_id],]\n",
    "    b = (a != 0).any()\n",
    "    return a.columns[b].tolist()\n",
    "\n",
    "#user_to_recommend takes in a string of customer_id\n",
    "def get_kitems_customer_recommendations(topk, user_to_recommend, neighbours, popular_products, similarity_matrix):\n",
    "    #user_to_Recommend: customer_id, indicate who we are going to recommend products for\n",
    "    #neighbours: neighbours dataframe\n",
    "    #popular_products: a list of most popular products for the customer's age group\n",
    "    if user_to_recommend in neighbours.index:\n",
    "        neighbour_customer = neighbours.loc[[user_to_recommend],].values #list of neighbours\n",
    "        purchased_items = purchased_products(similarity_matrix, user_to_recommend)\n",
    "        recommendation = []\n",
    "        for neighbour in neighbour_customer[0]:\n",
    "            recommendation.extend(purchased_products(similarity_matrix, neighbour))\n",
    "        #remove purchased items from recommendation\n",
    "        recommendation = [x for x in recommendation if x not in purchased_items]\n",
    "        n_items = len(recommendation)\n",
    "        if n_items >= topk:\n",
    "            return recommendation[:topk]\n",
    "        else:\n",
    "            gap = topk - n_items\n",
    "            for i in range(gap):\n",
    "                recommendation.append(popular_products[i])\n",
    "            return recommendation\n",
    "    else:\n",
    "        return popular_products[:topk]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-organic",
   "metadata": {},
   "source": [
    "### 5.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#for evaluation, we take the first 6 digits of article_id, which represents the product_code\n",
    "results = pd.DataFrame(columns=['customer_id', 'article_id', 'predicted_y'])\n",
    "for customer, age_group in zip(test_set['customer_id'], test_set['age_group']):\n",
    "    recommendations = get_kitems_customer_recommendations(12, customer, neighbours, popular_product[age_group-1], similarity_matrix)\n",
    "    for product in recommendations:\n",
    "        results = results.append({'customer_id': customer, 'article_id': str(product)[:6], 'predicted_y': 1}, ignore_index=True)        \n",
    "test_set.article_id = test_set.article_id.astype(str)\n",
    "test_set['article_id'] = test_set['article_id'].str[:6]\n",
    "\n",
    "def update_user_choices(row):\n",
    "    customer = row['customer_id']\n",
    "    article = row['article_id']\n",
    "    search = test_set.loc[(test_set.customer_id == customer) & (test_set.article_id == article), ]\n",
    "    if len(search)>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#update actual purchase\n",
    "results['actual_y'] = results.apply(update_user_choices, axis=1)\n",
    "\n",
    "#Compute MAP for the model\n",
    "results = results.drop([\"predicted_y\",\"actual_y\"],axis=1)\n",
    "train_unq = results.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "train_unq['valid_pred'] = train_unq['article_id'].map(lambda x: (str(x)[1:-1]))\n",
    "valid_unq = test_set.groupby('customer_id')['article_id'].apply(list).reset_index()\n",
    "valid_unq['valid_true'] = valid_unq['article_id'].map(lambda x: str(x)[1:-1])\n",
    "\n",
    "merged = pd.merge(train_unq, valid_unq, on='customer_id', how='left').fillna('')\n",
    "merged = merged.drop([\"article_id_x\",\"article_id_y\"],axis=1)\n",
    "merged = merged[merged['valid_true']!=''].reset_index(drop=True)\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n",
    "\n",
    "\n",
    "# MAP calculation\n",
    "mapk(merged['valid_true'].map(lambda x: x.split()), \n",
    "    merged['valid_pred'].map(lambda x: x.split()), \n",
    "    k=12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-convert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
